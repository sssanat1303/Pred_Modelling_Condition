```{r include = FALSE}
knitr::opts_chunk$set(message = FALSE)

```



```{r include = FALSE}
library(ggplot2)
library(tidyverse)
library(readxl)
library(lubridate)
library(corrplot)
library(naniar)
library(keras)
library(glmnet)
library(xgboost)
library(finalfit)
library(rpart)
library(MASS)
library(ranger)

myfit <- function(train_df, test_df, a = 0){
  
  train_X <- as.matrix(train_df %>% dplyr::select(-Y))
  train_y <- train_df$Y
  test_X <- as.matrix(test_df %>% dplyr::select(-Y))
  test-y <- test_df$Y
  
  
  cv.fit <- glmnet(train_X, train_y, alpha = a, lambda = lambdas)
  plot(cv.fit)
  
  
  opt.1 <- cv.fit$lambda.min
  opt.fit <- cv.fit$glmnet.fit
  bets <- as.matrix(coef(opt.fit, s = cv.fit$lambda.min))
  n_non0_betas <- sum(betas!=0)
  
  pred_y <- predict(opt.fit, s = opt.1, newx = test_X)
  mse <- mean((test_y - pred_y)^2)
  
  
  return(list(alpha = a, mse = mse, opt.lambda = opt.1, 
              n_non0_betas = n_non0_betas))
  
  
}


allyhat <- function(xtrain, ytrain, xtest, lambdas, nvmax) {
  n <- nrow(xtrain)
  yhat <- matrix(nrow=nrow(xtest), ncol=length(lambdas))
  search <-  regsubsets(xtrain, ytrain, nvmax, method = "back")
  summ <- summary(search)
  
  for(i in 1:length(lambdas)) {
    penMSE <- n*log(summ$rss) + lambdas[i]*(1:nvmax)
    best <- which.min(penMSE)
    betahat <- coef(search, best)
    xinmodel <- cbind(1, xtest)[,summ$which[best, ]]
    yhat[, i] <- xinmodel%*%betahat
  }
  
  yhat
}


```


## Waste Water Transmission Network Modelling 


### Creating Training and Testing Datasets

The first thing to do would be to separate the WWT data set into CCTV positive and CCTV negative aand then further remove variables that are not going to inform our predictive models. 

```{r}
WWT.yes <- WWT.modelling %>% filter(condition_CCTV_app_availability == "yes")
WWT.no <- WWT.modelling %>% filter(condition_CCTV_app_availability == "no")
missing_plot(WWT.yes)
missing_plot(WWT.no)

```
```{r}
WWT.yes <- WWT.yes[, -9]
WWT.no <- WWT.no[, -9]
```

Unfortunately, when we do this split, the high cctv availability pipes have no pipes with a condition of 5. This is going to be probablmatic, as cctv availablity pipes are going to be our training data. This means that our model will have no knowledge on how to predict level 5 condition pipes. 

We need to maintain a distribution of our condition that is consistent with our population dataset 

```{r}
summary(WWT.modelling$condition_overall_score_label)
```
```{r}
summary(WWT.yes$condition_overall_score_label)
summary(WWT.no$condition_overall_score_label)
```
I think the only statistically sound way to fix this is to migrate some low confidence data to the high confidence data (map some pipes from no cctv availability to yes cctv availability) 


```{r}
set.seed(123)
rows_to_move <- which(WWT.no$condition_overall_score_label == "5")
num_to_select <- min(10, length(rows_to_move))
selected_rows <- sample(rows_to_move, num_to_select)

WWT.yes <- WWT.yes %>% rbind(WWT.no[selected_rows, ])
WWT.no <- WWT.no[-selected_rows,]


summary(WWT.yes$condition_overall_score_label)
summary(WWT.no$condition_overall_score_label)
```


### Decision Tree 


```{r}

set.seed(749)
sample.index <- sample(1:nrow(WWT.yes), size = 0.8 * nrow(WWT.yes))
WWT.yes.train <- WWT.yes[sample.index, ]
WWT.yes.test <- WWT.yes[-sample.index, ]

condition.tree1 <- rpart(condition_overall_score_label~., data = WWT.yes.train)
plotcp(condition.tree1)
```
```{r}
predict1 <- predict(condition.tree1, WWT.yes.test, type = "class")
confMatrix1 <- table(Actual = WWT.yes.test$condition_overall_score_label, Predicted = predict1)
confMatrix1
```

```{r}
sum(diag(confMatrix1)) / nrow(WWT.yes.test)
```
```{r}
plot(condition.tree1, margin = 0.02)
text(condition.tree1, pretty = 2)
```

```{r}
printcp(condition.tree1)
```
Pruned this tree to a cp of 0.028571

```{r}
condition.tree2 <- rpart(condition_overall_score_label~., data = WWT.yes.train, cp =0.028751)
plotcp(condition.tree2)
predict2 <- predict(condition.tree2, WWT.yes.test, type = "class")
confMatrix2 <- table(Actual = WWT.yes.test$condition_overall_score_label, Predicted = predict2)
confMatrix2
sum(diag(confMatrix2)) / nrow(WWT.yes.test)
plot(condition.tree2)
```


#### Prediction on low confidence dataset

```{r}
predict3 <- predict(condition.tree2, WWT.no, type = "class")
confMatrix3 <- table(Actual = WWT.no$condition_overall_score_label, Predicted = predict3)
confMatrix3
sum(diag(confMatrix3)) / nrow(WWT.no)
```



### Random Forest


```{r}
rf_model <- ranger(condition_overall_score_label ~ ., data = WWT.yes.train, trees = 10000, mtry = 5)
predict4 <- predict(rf_model, WWT.yes.test)$predictions
confMatrix4 <- table(Actual = WWT.yes.test$condition_overall_score_label, Predicted = predict4)
confMatrix4
sum(diag(confMatrix4)) / nrow(WWT.yes.test)
```


#### Predictions on actual model

```{r}
predict5 <- predict(rf_model, WWT.no)$predictions
confMatrix5 <- table(Actual = WWT.no$condition_overall_score_label, Predicted = predict5)
confMatrix5
sum(diag(confMatrix5)) / nrow(WWT.no)
```


### Gradient Boosting Model


#### Model Performance



### Artificial Neural Network Model


#### Model Performance




## Model Choice and Justifcation 



### Predictions on low confidence data and analysis of results

